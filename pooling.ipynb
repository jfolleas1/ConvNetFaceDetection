{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# Constant\n",
    "SIZE_FILTER_X = 36\n",
    "SIZE_FILTER_Y = 36\n",
    "NB_ITERATION = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_keras(path_to_model):\n",
    "    return load_model(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_rectangle(list_point, step_x, step_y):\n",
    "    has_changed = True\n",
    "    while(has_changed):\n",
    "        has_changed = False\n",
    "        temp_result = []\n",
    "        list_indice = []\n",
    "        for i in range(len(list_point)):\n",
    "            Added_new_element = False\n",
    "            for j in range(i+1, len(list_point)):\n",
    "                if (math.fabs(list_point[i][0] - list_point[j][0]) <= 3*step_x and\n",
    "                    math.fabs(list_point[i][1] - list_point[j][1]) <= 3*step_y and j not in list_indice):\n",
    "                    \n",
    "                    temp_result.append((int((list_point[i][0] + list_point[j][0])/2), int((list_point[i][1] + list_point[j][1])/2)))\n",
    "                    list_indice.append(j)\n",
    "                    Added_new_element = True\n",
    "                    \n",
    "            if Added_new_element == False and i not in list_indice:\n",
    "                temp_result.append(list_point[i])\n",
    "                \n",
    "            has_changed = has_changed | Added_new_element\n",
    "            \n",
    "        list_point = copy.deepcopy(temp_result)\n",
    "    \n",
    "    return list_point\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_visage(gray_image, size_filter_X, size_filter_Y, model):\n",
    "    \n",
    "    # Raise an exception, if we can't apply the fitlter\n",
    "    width, height = gray_image.shape[0], gray_image.shape[1]\n",
    "    \n",
    "    if width < size_filter_Y and height < size_filter_X :\n",
    "        raise Exception (\"impossible to crop properly\")\n",
    "        \n",
    "    if (size_filter_X/2) % 2 != 0 or (size_filter_Y/2) % 2 != 0:\n",
    "        raise Exception (\"All dimension of the filter should be pair\")\n",
    "    \n",
    "    # loop on the image.\n",
    "    fil_divi_2_X = int (size_filter_X/2)\n",
    "    fil_divi_2_Y = int (size_filter_Y/2)\n",
    "    step_x = int(fil_divi_2_X/3)\n",
    "    step_y = int(fil_divi_2_Y/3)\n",
    "    result = []\n",
    "    listImgPos = []\n",
    "    for y in range(fil_divi_2_X, height - fil_divi_2_X, step_x):\n",
    "        for x in range(fil_divi_2_Y, width - fil_divi_2_Y, step_y):\n",
    "            crop_img = gray_image[y - fil_divi_2_Y: y + fil_divi_2_Y, x - fil_divi_2_X : x + fil_divi_2_X]\n",
    "            \n",
    "            crop_imag_copy  = copy.deepcopy(crop_img)\n",
    "            \n",
    "            crop_img = np.array(crop_img)\n",
    "            crop_img.resize((1,36,36,1))\n",
    "            \n",
    "            if int(model.predict(crop_img,verbose = 0)[0] + 0.0005) == 1:\n",
    "                print (\"GET A VISAGE\")\n",
    "                result.append((x,y))\n",
    "                listImgPos.append(crop_imag_copy)\n",
    "            \n",
    "    return compute_mean_rectangle(result, step_x, step_y), listImgPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(img, cor_x, cor_y, size_filter_X, size_filter_Y ):\n",
    "    print(\"ADD RECTANGLE\")\n",
    "    fil_divi_2_X = int (size_filter_X/2)\n",
    "    fil_divi_2_Y = int (size_filter_Y/2)\n",
    "    cv2.rectangle(img, (cor_x - fil_divi_2_X, cor_y - fil_divi_2_Y), (cor_x + fil_divi_2_X, cor_y + fil_divi_2_Y), (255,0,0), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid_search (path_image, size_filter_X, size_filter_Y, nb_iterations, model):\n",
    "    # We get and tranform the image in gray.\n",
    "    img_search = cv2.imread(path_image)\n",
    "    gray_image = cv2.cvtColor(img_search, cv2.COLOR_BGR2GRAY)\n",
    "    gray_imag_rect  = copy.deepcopy(gray_image)\n",
    "    \n",
    "    # Make the reduction.\n",
    "    # --> search\n",
    "    height, width = gray_image.shape\n",
    "    nbPixelToReduceX = int((width  - size_filter_X) / nb_iterations)\n",
    "    nbPixelToReduceY = int((height - size_filter_Y) / nb_iterations)\n",
    "    \n",
    "    \n",
    "    for ite in range(nb_iterations) :\n",
    "        \n",
    "        height, width = gray_image.shape\n",
    "        \n",
    "        if(ite == nb_iterations-1):\n",
    "            gray_image = cv2.resize(gray_image, (size_filter_X, size_filter_Y)) # Last iteration\n",
    "            size_filter_X_new = width - nbPixelToReduceX\n",
    "            size_filter_Y_new = height - nbPixelToReduceY\n",
    "            height, width = gray_image.shape\n",
    "        elif(ite == 0):\n",
    "            size_filter_X_new = size_filter_X - nbPixelToReduceX\n",
    "            size_filter_Y_new = size_filter_Y - nbPixelToReduceY\n",
    "        else :\n",
    "            gray_image = cv2.resize(gray_image, (width - nbPixelToReduceX, height - nbPixelToReduceY))   \n",
    "        \n",
    "        gray_imag_rect_copy  = copy.deepcopy(gray_image)\n",
    "            \n",
    "        # we get all square that seems to be a visage.\n",
    "        result, listImgPos = search_visage(gray_image, size_filter_X, size_filter_Y, model)\n",
    "        \n",
    "        size_filter_X_new = nbPixelToReduceX + size_filter_X_new\n",
    "        size_filter_Y_new = nbPixelToReduceY + size_filter_Y_new\n",
    "        \n",
    "        \n",
    "        # draw red rectangle.\n",
    "        for x, y in result: \n",
    "            gray_imag_rect = draw_rectangle(gray_image, x, y, size_filter_X, size_filter_Y)\n",
    "        \n",
    "        \n",
    "        ## Display positives images\n",
    "        #for l in listImgPos :\n",
    "        #    plt.figure()\n",
    "        #    plt.imshow(l)\n",
    "            \n",
    "        ## Display initial image with reds rectangles. \n",
    "        if(result == []) :\n",
    "            plt.figure()\n",
    "            plt.imshow(gray_image)\n",
    "        else :\n",
    "            plt.figure()\n",
    "            plt.imshow(gray_imag_rect)\n",
    "        \n",
    "        # Remove rectangle before next iteration.\n",
    "        gray_image = gray_imag_rect_copy       \n",
    "        \n",
    "    return gray_imag_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`load_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2298c4a352b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyramid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hulk.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE_FILTER_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE_FILTER_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNB_ITERATION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-91eadf9cc209>\u001b[0m in \u001b[0;36mload_model_keras\u001b[0;34m(path_to_model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/ConvNetFaceDetection/virtualenv/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \"\"\"\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_model` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `load_model` requires h5py."
     ]
    }
   ],
   "source": [
    "model = load_model_keras('my_model.h5')\n",
    "result = pyramid_search('hulk.jpg', SIZE_FILTER_X, SIZE_FILTER_Y, NB_ITERATION, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
