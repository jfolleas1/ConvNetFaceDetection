{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport script_hard_example"
    "from sklearn.cluster import DBSCAN\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# Constant\n",
    "SIZE_FILTER_X = 36\n",
    "SIZE_FILTER_Y = 36\n",
    "NB_ITERATION = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model_keras(path_to_model):\n",
    "    return load_model(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mean_rectangle(list_point, step_x, step_y):\n",
    "    has_changed = True\n",
    "    while(has_changed):\n",
    "        has_changed = False\n",
    "        temp_result = []\n",
    "        list_indice = []\n",
    "        for i in range(len(list_point)):\n",
    "            Added_new_element = False\n",
    "            for j in range(i+1, len(list_point)):\n",
    "                if (math.fabs(list_point[i][0] - list_point[j][0]) <= 3*step_x and\n",
    "                    math.fabs(list_point[i][1] - list_point[j][1]) <= 3*step_y and j not in list_indice):\n",
    "                    \n",
    "                    temp_result.append((int((list_point[i][0] + list_point[j][0])/2), int((list_point[i][1] + list_point[j][1])/2)))\n",
    "                    list_indice.append(j)\n",
    "                    Added_new_element = True\n",
    "                    \n",
    "            if Added_new_element == False and i not in list_indice:\n",
    "                temp_result.append(list_point[i])\n",
    "                \n",
    "            has_changed = has_changed | Added_new_element\n",
    "            \n",
    "        list_point = copy.deepcopy(temp_result)\n",
    "    \n",
    "    return list_point\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_visage(gray_image, size_filter_X, size_filter_Y, model):\n",
    "    \n",
    "    # Raise an exception, if we can't apply the fitlter\n",
    "    width, height = gray_image.shape[0], gray_image.shape[1]\n",
    "    \n",
    "    if width < size_filter_Y and height < size_filter_X :\n",
    "        raise Exception (\"impossible to crop properly\")\n",
    "        \n",
    "    if (size_filter_X/2) % 2 != 0 or (size_filter_Y/2) % 2 != 0:\n",
    "        raise Exception (\"All dimension of the filter should be pair\")\n",
    "    \n",
    "    # loop on the image.\n",
    "    fil_divi_2_X = int (size_filter_X/2)\n",
    "    fil_divi_2_Y = int (size_filter_Y/2)\n",
    "    step_x = int(fil_divi_2_X/3)\n",
    "    step_y = int(fil_divi_2_Y/3)\n",
    "    result = []\n",
    "    listImgPos = []\n",
    "    for y in range(fil_divi_2_X, height - fil_divi_2_X, step_x):\n",
    "        for x in range(fil_divi_2_Y, width - fil_divi_2_Y, step_y):\n",
    "            crop_img = gray_image[y - fil_divi_2_Y: y + fil_divi_2_Y, x - fil_divi_2_X : x + fil_divi_2_X]\n",
    "            \n",
    "            crop_imag_copy  = copy.deepcopy(crop_img)\n",
    "            \n",
    "            crop_img = np.array(crop_img)\n",
    "            crop_img.resize((1,36,36,1))\n",
    "            \n",
    "            # print('LOG - ', model.predict(crop_img,verbose = 0)[0])\n",
    "            if int(model.predict(crop_img,verbose = 0)[0][1] + 0.1) == 1:\n",
    "            # if int(model.predict(crop_img,verbose = 0)[0] + 0.5) == 1:\n",
    "                # print (\"GET A VISAGE\")\n",
    "                result.append((x,y))\n",
    "                listImgPos.append(crop_imag_copy)\n",
    "    return compute_mean_rectangle(result, step_x, step_y), listImgPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_rectangle(img, cor_x, cor_y, size_filter_X, size_filter_Y ):\n",
    "    # print(\"ADD RECTANGLE\")\n",
    "    fil_divi_2_X = int (size_filter_X/2)\n",
    "    fil_divi_2_Y = int (size_filter_Y/2)\n",
    "    cv2.rectangle(img, (cor_x - fil_divi_2_X, cor_y - fil_divi_2_Y), (cor_x + fil_divi_2_X, cor_y + fil_divi_2_Y), (0,255,0), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pyramid_search (path_image, size_filter_X, size_filter_Y, nb_iterations, model):\n",
    "    # We get and tranform the image in gray.\n",
    "    img_search = cv2.imread(path_image)\n",
    "    gray_image = cv2.cvtColor(img_search, cv2.COLOR_BGR2GRAY)\n",
    "    gray_imag_rect  = copy.deepcopy(gray_image)\n",
    "    \n",
    "    # Make the reduction.\n",
    "    # --> search\n",
    "    height, width = gray_image.shape\n",
    "    nbPixelToReduceX = int(int(width  - size_filter_X) / (nb_iterations-1))\n",
    "    nbPixelToReduceY = int(int(height - size_filter_Y) / (nb_iterations-1))\n",
    "    \n",
    "    results = []\n",
    "    for ite in range(nb_iterations) :\n",
    "        \n",
    "        height, width = gray_image.shape\n",
    "        \n",
    "        if(ite == nb_iterations-1):\n",
    "            gray_image = cv2.resize(gray_image, (size_filter_X, size_filter_Y)) # Last iteration\n",
    "            size_filter_X_new = width - nbPixelToReduceX\n",
    "            size_filter_Y_new = height - nbPixelToReduceY\n",
    "            height, width = gray_image.shape\n",
    "        elif(ite == 0):\n",
    "            size_filter_X_new = size_filter_X - nbPixelToReduceX\n",
    "            size_filter_Y_new = size_filter_Y - nbPixelToReduceY\n",
    "        else :\n",
    "            gray_image = cv2.resize(gray_image, (width - nbPixelToReduceX, height - nbPixelToReduceY))   \n",
    "        \n",
    "        gray_imag_rect_copy  = copy.deepcopy(gray_image)\n",
    "            \n",
    "        # we get all square that seems to be a visage.\n",
    "        result, listImgPos = search_visage(gray_image, size_filter_X, size_filter_Y, model)\n",
    "        \n",
    "        size_filter_X_new = nbPixelToReduceX + size_filter_X_new\n",
    "        size_filter_Y_new = nbPixelToReduceY + size_filter_Y_new\n",
    "        \n",
    "        results += result\n",
    "        # draw red rectangle.\n",
    "        for x, y in result:\n",
    "            print('(x, y) = (', x, ', ', y, ') on image : ', gray_image.shape )\n",
    "            gray_imag_rect = draw_rectangle(gray_image, x, y, size_filter_X, size_filter_Y)\n",
    "        \n",
    "        \n",
    "        ## Display positives images\n",
    "        #for l in listImgPos :\n",
    "        #    plt.figure()\n",
    "        #    plt.imshow(l)\n",
    "            \n",
    "        ## Display initial image with reds rectangles. \n",
    "        if(result == []) :\n",
    "            plt.figure()\n",
    "            plt.imshow(gray_image)\n",
    "        else :\n",
    "            plt.figure()\n",
    "            plt.imshow(gray_imag_rect)\n",
    "        \n",
    "        # Remove rectangle before next iteration.\n",
    "        gray_image = gray_imag_rect_copy       \n",
    "        \n",
    "    return gray_imag_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid_search_all (path_image, size_filter_X, size_filter_Y, nb_iterations, model):\n",
    "    print('Searching faces on different scales of the image ...')\n",
    "    # We get and tranform the image in gray.\n",
    "    img_search = cv2.imread(path_image)\n",
    "    gray_image = cv2.cvtColor(img_search, cv2.COLOR_BGR2GRAY)\n",
    "    gray_imag_rect  = copy.deepcopy(gray_image)\n",
    "    orig_imag = copy.deepcopy(gray_image)\n",
    "    origin_height, origin_width = orig_imag.shape\n",
    "    # Make the reduction.\n",
    "    # --> search\n",
    "    height, width = gray_image.shape\n",
    "    nbPixelToReduceX = int(int(width  - size_filter_X) / (nb_iterations-1))\n",
    "    nbPixelToReduceY = int(int(height - size_filter_Y) / (nb_iterations-1))\n",
    "    \n",
    "    results = []\n",
    "    for ite in range(nb_iterations) :\n",
    "        \n",
    "        height, width = gray_image.shape\n",
    "        \n",
    "        if(ite == nb_iterations-1):\n",
    "            gray_image = cv2.resize(gray_image, (size_filter_X, size_filter_Y)) # Last iteration\n",
    "            size_filter_X_new = width - nbPixelToReduceX\n",
    "            size_filter_Y_new = height - nbPixelToReduceY\n",
    "            height, width = gray_image.shape\n",
    "        elif(ite == 0):\n",
    "            size_filter_X_new = size_filter_X - nbPixelToReduceX\n",
    "            size_filter_Y_new = size_filter_Y - nbPixelToReduceY\n",
    "        else :\n",
    "            gray_image = cv2.resize(gray_image, (width - nbPixelToReduceX, height - nbPixelToReduceY))   \n",
    "        \n",
    "        gray_imag_rect_copy  = copy.deepcopy(gray_image)\n",
    "            \n",
    "        # we get all square that seems to be a visage.\n",
    "        result, listImgPos = search_visage(gray_image, size_filter_X, size_filter_Y, model)\n",
    "        \n",
    "        size_filter_X_new = nbPixelToReduceX + size_filter_X_new\n",
    "        size_filter_Y_new = nbPixelToReduceY + size_filter_Y_new\n",
    "        \n",
    "        nh, nw = gray_image.shape\n",
    "        w = origin_width/nw\n",
    "        h = origin_height/nh\n",
    "        # draw red rectangle.\n",
    "        for x, y in result:\n",
    "            results.append((int(x*w), int(y*h), int(size_filter_X*w), int(size_filter_Y*h)))\n",
    "    \n",
    "    \n",
    "        \n",
    "    return orig_imag, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangles_all(orig_imag, results) :\n",
    "    # draw red rectangle.\n",
    "    for x, y, w, h in results:\n",
    "        gray_imag_rect = draw_rectangle(orig_imag, x, y, w, h)\n",
    "\n",
    "    ## Display initial image with reds rectangles. \n",
    "    if(results == []) :\n",
    "        plt.figure()\n",
    "        plt.imshow(orig_imag)\n",
    "    else :\n",
    "        plt.figure()\n",
    "        plt.imshow(gray_imag_rect)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_rect(rectangles, img_w, img_h) :\n",
    "    X =[]\n",
    "    nb = len(rectangles)\n",
    "    for x, y, w, h in rectangles :\n",
    "        X.append([x, y])\n",
    "    eps = max([x[2] for x in rectangles])/3\n",
    "    print('eps = ', eps)\n",
    "    db = DBSCAN(eps=eps, min_samples=5).fit(X)\n",
    "    \n",
    "    labels = db.labels_\n",
    "    print(labels)\n",
    "    clusters = {}\n",
    "    for i in range(0, len(labels)) : \n",
    "        if labels[i] != -1 :\n",
    "            if labels[i] in clusters :\n",
    "                if rectangles[i][2] > clusters[labels[i]][2] :\n",
    "                    clusters[labels[i]] = rectangles[i]\n",
    "            else :\n",
    "                clusters[labels[i]] = rectangles[i]\n",
    "    results = []\n",
    "    for c in clusters :\n",
    "        results.append(clusters[c])\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = load_model_keras('model_n.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in listdir('./img/') :\n",
    "    img_org, res = pyramid_search_all('./img/' + path, SIZE_FILTER_X, SIZE_FILTER_Y, NB_ITERATION, model)\n",
    "    img_h, img_w = img_org.shape\n",
    "    img = copy.deepcopy(img_org)\n",
    "    print('Before merging the rectangles')\n",
    "    draw_rectangles_all(img, res)\n",
    "    results = merge_rect(res, img_w, img_h)\n",
    "    img_c = copy.deepcopy(img_org)\n",
    "    print('After merging the rectangles')\n",
    "    draw_rectangles_all(img_c, results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model_hard_train_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>HARD Example</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pyramid_search_difficult (path_image, size_filter_X, size_filter_Y, nb_iterations, model, threshold):\n",
    "    # We get and tranform the image in gray.\n",
    "    img_search = cv2.imread(path_image)\n",
    "    gray_image = cv2.cvtColor(img_search, cv2.COLOR_BGR2GRAY)\n",
    "    gray_imag_rect  = copy.deepcopy(gray_image)\n",
    "    \n",
    "    # Make the reduction.\n",
    "    # --> search\n",
    "    height, width = gray_image.shape\n",
    "    nbPixelToReduceX = int((width  - size_filter_X) / (nb_iterations -1) )\n",
    "    nbPixelToReduceY = int((height - size_filter_Y) / (nb_iterations -1) ) \n",
    "    \n",
    "    list_reponse = []\n",
    "    for ite in range(nb_iterations) :\n",
    "        \n",
    "        height, width = gray_image.shape\n",
    "        \n",
    "        if(ite == nb_iterations-1):\n",
    "            gray_image = cv2.resize(gray_image, (size_filter_X, size_filter_Y)) # Last iteration\n",
    "            size_filter_X_new = width - nbPixelToReduceX\n",
    "            size_filter_Y_new = height - nbPixelToReduceY\n",
    "            height, width = gray_image.shape\n",
    "        elif(ite == 0):\n",
    "            size_filter_X_new = size_filter_X - nbPixelToReduceX\n",
    "            size_filter_Y_new = size_filter_Y - nbPixelToReduceY\n",
    "        else :\n",
    "            gray_image = cv2.resize(gray_image, (width - nbPixelToReduceX, height - nbPixelToReduceY))   \n",
    "        \n",
    "        gray_imag_rect_copy  = copy.deepcopy(gray_image)\n",
    "        \n",
    "        # we get a list of all visage.\n",
    "        list_reponse = list_reponse + search_visage(gray_image, size_filter_X, size_filter_Y, model, threshold)\n",
    "        \n",
    "    return list_reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_visage(gray_image, size_filter_X, size_filter_Y, model, threshold):\n",
    "    \n",
    "    # Raise an exception, if we can't apply the fitlter\n",
    "    width, height = gray_image.shape[0], gray_image.shape[1]\n",
    "    \n",
    "    if width < size_filter_Y and height < size_filter_X :\n",
    "        raise Exception (\"impossible to crop properly\")\n",
    "        \n",
    "    if (size_filter_X/2) % 2 != 0 or (size_filter_Y/2) % 2 != 0:\n",
    "        raise Exception (\"All dimension of the filter should be pair\")\n",
    "    \n",
    "    # loop on the image.\n",
    "    fil_divi_2_X = int (size_filter_X/2)\n",
    "    fil_divi_2_Y = int (size_filter_Y/2)\n",
    "    step_x = int(fil_divi_2_X/3)\n",
    "    step_y = int(fil_divi_2_Y/3)\n",
    "    listImgPos = []\n",
    "    for y in range(fil_divi_2_X, height - fil_divi_2_X, step_x):\n",
    "        for x in range(fil_divi_2_Y, width - fil_divi_2_Y, step_y):\n",
    "            crop_img = gray_image[y - fil_divi_2_Y: y + fil_divi_2_Y, x - fil_divi_2_X : x + fil_divi_2_X]\n",
    "            \n",
    "            crop_imag_copy  = copy.deepcopy(crop_img)\n",
    "            crop_img = np.array(crop_img)\n",
    "            crop_img.resize((1,36,36,1))\n",
    "            \n",
    "            if int(model.predict(crop_img,verbose = 0)[0] + threshold) == 1:\n",
    "                listImgPos.append(crop_imag_copy)\n",
    "\n",
    "    return listImgPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path_repo = \"data_difficult_faces/0/\"\n",
    "path_save = \"data_save_difficult_no_faces/\"\n",
    "def find_and_save_difficult_images(path_repo, path_save, threshold, model, indice):\n",
    "    list_image = []\n",
    "    # get the image.\n",
    "    for index, filename in enumerate(os.listdir(path_repo)):\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "        list_difficult_faces =  pyramid_search_difficult(os.path.join(path_repo, filename), SIZE_FILTER_X, SIZE_FILTER_Y, NB_ITERATION, model, threshold)\n",
    "        print(\"Traite l'image : \"+ str(index) + \" find : \"+ str(len (list_difficult_faces)))\n",
    "        list_image +=  list_difficult_faces\n",
    "    \n",
    "    max_indice = 0    \n",
    "    for index, image in enumerate(list_image):\n",
    "        width, height = image.shape[0], image.shape[1]\n",
    "        max_indice = indice + index\n",
    "        if width == 36 and height == 36:\n",
    "            cv2.imwrite(os.path.join(path_save, str(max_indice) + \".jpg\"), image) \n",
    "            print()\n",
    "    \n",
    "    return max_indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.7\n",
    "def update_model (path_save, threshold):\n",
    "    path_repo = \"data_difficult_faces/\"\n",
    "    indice = 0\n",
    "    threshold = 0.2\n",
    "    model = None\n",
    "    \n",
    "    lenght_repo = 0\n",
    "    if \".DS_Store\" in os.listdir(\"data_difficult_faces/\"):\n",
    "        lenght_repo = len(os.listdir(\"data_difficult_faces/\"))-1\n",
    "    else:\n",
    "        lenght_repo = len(os.listdir(\"data_difficult_faces/\"))-1\n",
    "        \n",
    "    for ite in range(lenght_repo):\n",
    "        print (\"iteration : \" + str(ite) + \" threshold : \"+  str(1-threshold))\n",
    "        cur_path_rep = path_repo + str(ite) + \"/\"\n",
    "        print(cur_path_rep)\n",
    "        model = script_hard_example.get_model(1)\n",
    "        indice += find_and_save_difficult_images(cur_path_rep, path_save, threshold, model, indice)\n",
    "        threshold = threshold * THRESHOLD\n",
    "            model.save('model_it'+ str(ite) +''.h5')\n",
    "    \n",
    "\n",
    "    model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_model(path_save, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
