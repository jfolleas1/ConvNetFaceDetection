{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Find hard example and update the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "import cv2\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from os import listdir\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load create_model_with_hard_example.py\n",
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "TRAIN_1_DIR = './data/train/1/'\n",
    "TRAIN_0_DIR = './data/train/0/'\n",
    "HARD_EXAMPLE_DIR = 'data_save_difficult_no_faces/'\n",
    "\n",
    "\n",
    "ROWS = 36\n",
    "COLS = 36\n",
    "CHANNELS = 1\n",
    "\n",
    "\n",
    "TRIAN_1_PATH = list(filter(lambda x: '.DS' not in x,[TRAIN_1_DIR+i for i in os.listdir(TRAIN_1_DIR)]))\n",
    "TRIAN_0_PATH = list(filter(lambda x: '.DS' not in x,[TRAIN_0_DIR+i for i in os.listdir(TRAIN_0_DIR)]))\n",
    "\n",
    "\n",
    "NB_TEST_BY_CLASS = 3000\n",
    "\n",
    "NB_EPOCH = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "##\n",
    "# Read the images at the indicate path and return a vectorized image\n",
    "##\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) #\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "##\n",
    "# Takes a lists of images path and return a list of vectorized images\n",
    "##\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image\n",
    "    \n",
    "    return data\n",
    "\n",
    "TRIAN_1_IMAGES = prep_data(TRIAN_1_PATH)\n",
    "TRIAN_0_IMAGES = prep_data(TRIAN_0_PATH)\n",
    "\n",
    "##\n",
    "# shuffle the set of train images\n",
    "##\n",
    "def shuffle_and_get_new_train_set():\n",
    "    random.shuffle(TRIAN_1_IMAGES)\n",
    "    random.shuffle(TRIAN_0_IMAGES)\n",
    "    test_images_1 = TRIAN_1_IMAGES[:NB_TEST_BY_CLASS]\n",
    "    test_images_0 = TRIAN_0_IMAGES[:NB_TEST_BY_CLASS]\n",
    "    train_1 = TRIAN_1_IMAGES[NB_TEST_BY_CLASS:]\n",
    "    train_0 = TRIAN_0_IMAGES[NB_TEST_BY_CLASS:]\n",
    "    return train_1, train_0, test_images_1, test_images_0\n",
    "\n",
    "##\n",
    "# reutrn the train set and the test set of images and coresponding labels \n",
    "##\n",
    "def prepar_train_images():\n",
    "    hard_example_paths = list(filter(lambda x: '.DS' not in x,[HARD_EXAMPLE_DIR+i for i in os.listdir(HARD_EXAMPLE_DIR)]))\n",
    "    hard_example_set = prep_data(hard_example_paths)\n",
    "    train_1, train_0, test_images_1, test_images_0 = shuffle_and_get_new_train_set()\n",
    "    print(\"inside function : \" + str(len(hard_example_set)))\n",
    "    train_images = np.array(list(train_1[:(len(train_0)+len(hard_example_set))]) +\n",
    "                            list(train_0) + list(hard_example_set))\n",
    "    train_images.resize((len(train_images), 36, 36, 1))\n",
    "    train_and_label = list(zip(train_images, ([1]*(len(train_images)//2)) + ([0]*(len(train_images)//2))))\n",
    "    random.shuffle(train_and_label)\n",
    "    train_images = list(map(lambda x: x[0], train_and_label))\n",
    "    train_labels = list(map(lambda x: x[1], train_and_label))\n",
    "    test_imagies = list(test_images_1) + list(test_images_0)\n",
    "    test_imagies = np.array(test_imagies)\n",
    "    test_imagies.resize((NB_TEST_BY_CLASS*2, 36, 36, 1))\n",
    "    return np.array(train_images), np.array(train_labels), test_imagies\n",
    "\n",
    "##\n",
    "# Create the untrained model\n",
    "##\n",
    "def faceRecognition():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(4, 5, strides=(1,1), border_mode='same',\n",
    "                     input_shape=(36, 36, 1), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(14, 3, strides=(1,1), border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(14, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "##\n",
    "# train the model on the train set with the hard examples and return it\n",
    "##\n",
    "def get_model(verbose_train=0):\n",
    "    train_images, train_labels, test_imagies = prepar_train_images()\n",
    "    print(\"LEN train : \" + str(len(train_images)))\n",
    "\n",
    "\n",
    "    model = faceRecognition()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')\n",
    "    model.fit(train_images, train_labels, batch_size=BATCH_SIZE, nb_epoch=NB_EPOCH,\n",
    "                validation_split=0.25, verbose=verbose_train, shuffle=True, callbacks=[early_stopping])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constant\n",
    "path_repo = \"data_difficult_faces/0/\"\n",
    "path_save = \"data_save_difficult_no_faces/\"\n",
    "THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pyramid_search_difficult (path_image, size_filter_X, size_filter_Y, nb_iterations, model, threshold):\n",
    "    # We get and tranform the image in gray.\n",
    "    img_search = cv2.imread(path_image)\n",
    "    gray_image = cv2.cvtColor(img_search, cv2.COLOR_BGR2GRAY)\n",
    "    gray_imag_rect  = copy.deepcopy(gray_image)\n",
    "    \n",
    "    # Make the reduction.\n",
    "    # --> search\n",
    "    height, width = gray_image.shape\n",
    "    nbPixelToReduceX = int((width  - size_filter_X) / (nb_iterations -1) )\n",
    "    nbPixelToReduceY = int((height - size_filter_Y) / (nb_iterations -1) ) \n",
    "    \n",
    "    list_reponse = []\n",
    "    for ite in range(nb_iterations) :\n",
    "        \n",
    "        height, width = gray_image.shape\n",
    "        \n",
    "        if(ite == nb_iterations-1):\n",
    "            gray_image = cv2.resize(gray_image, (size_filter_X, size_filter_Y)) # Last iteration\n",
    "            size_filter_X_new = width - nbPixelToReduceX\n",
    "            size_filter_Y_new = height - nbPixelToReduceY\n",
    "            height, width = gray_image.shape\n",
    "        elif(ite == 0):\n",
    "            size_filter_X_new = size_filter_X - nbPixelToReduceX\n",
    "            size_filter_Y_new = size_filter_Y - nbPixelToReduceY\n",
    "        else :\n",
    "            gray_image = cv2.resize(gray_image, (width - nbPixelToReduceX, height - nbPixelToReduceY))   \n",
    "        \n",
    "        gray_imag_rect_copy  = copy.deepcopy(gray_image)\n",
    "        \n",
    "        # we get a list of all visage.\n",
    "        list_reponse = list_reponse + search_visage(gray_image, size_filter_X, size_filter_Y, model, threshold)\n",
    "        \n",
    "    return list_reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_visage(gray_image, size_filter_X, size_filter_Y, model, threshold):\n",
    "    \n",
    "    # Raise an exception, if we can't apply the fitlter\n",
    "    width, height = gray_image.shape[0], gray_image.shape[1]\n",
    "    \n",
    "    if width < size_filter_Y and height < size_filter_X :\n",
    "        raise Exception (\"impossible to crop properly\")\n",
    "        \n",
    "    if (size_filter_X/2) % 2 != 0 or (size_filter_Y/2) % 2 != 0:\n",
    "        raise Exception (\"All dimension of the filter should be pair\")\n",
    "    \n",
    "    # loop on the image.\n",
    "    fil_divi_2_X = int (size_filter_X/2)\n",
    "    fil_divi_2_Y = int (size_filter_Y/2)\n",
    "    step_x = int(fil_divi_2_X/3)\n",
    "    step_y = int(fil_divi_2_Y/3)\n",
    "    listImgPos = []\n",
    "    for y in range(fil_divi_2_X, height - fil_divi_2_X, step_x):\n",
    "        for x in range(fil_divi_2_Y, width - fil_divi_2_Y, step_y):\n",
    "            crop_img = gray_image[y - fil_divi_2_Y: y + fil_divi_2_Y, x - fil_divi_2_X : x + fil_divi_2_X]\n",
    "            \n",
    "            crop_imag_copy  = copy.deepcopy(crop_img)\n",
    "            crop_img = np.array(crop_img)\n",
    "            crop_img.resize((1,36,36,1))\n",
    "            \n",
    "            if int(model.predict(crop_img,verbose = 0)[0] + threshold) == 1:\n",
    "                listImgPos.append(crop_imag_copy)\n",
    "\n",
    "    return listImgPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_and_save_difficult_images(path_repo, path_save, threshold, model, indice):\n",
    "    list_image = []\n",
    "    # get the image.\n",
    "    for index, filename in enumerate(os.listdir(path_repo)):\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "        list_difficult_faces =  pyramid_search_difficult(os.path.join(path_repo, filename), SIZE_FILTER_X, SIZE_FILTER_Y, NB_ITERATION, model, threshold)\n",
    "        print(\"Traite l'image : \"+ str(index) + \" find : \"+ str(len (list_difficult_faces)))\n",
    "        list_image +=  list_difficult_faces\n",
    "    \n",
    "    max_indice = 0    \n",
    "    for index, image in enumerate(list_image):\n",
    "        width, height = image.shape[0], image.shape[1]\n",
    "        max_indice = indice + index\n",
    "        if width == 36 and height == 36:\n",
    "            cv2.imwrite(os.path.join(path_save, str(max_indice) + \".jpg\"), image) \n",
    "            print()\n",
    "    \n",
    "    return max_indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model (path_save, threshold):\n",
    "    path_repo = \"data_difficult_faces/\"\n",
    "    indice = 0\n",
    "    model = None\n",
    "    \n",
    "    lenght_repo = 0\n",
    "    if \".DS_Store\" in os.listdir(\"data_difficult_faces/\"):\n",
    "        lenght_repo = len(os.listdir(\"data_difficult_faces/\"))-1\n",
    "    else:\n",
    "        lenght_repo = len(os.listdir(\"data_difficult_faces/\"))-1\n",
    "        \n",
    "    \n",
    "    for ite in range(lenght_repo):\n",
    "        print (\"iteration : \" + str(ite) + \" threshold : \"+  str(1-threshold))\n",
    "        cur_path_rep = path_repo + str(ite) + \"/\"\n",
    "        print(cur_path_rep)\n",
    "        model = create_model_with_hard_example.get_model(1)\n",
    "        indice += find_and_save_difficult_images(cur_path_rep, path_save, threshold, model, indice)\n",
    "        threshold = threshold * THRESHOLD\n",
    "        model.save('model_it'+ str(ite) +'.h5')\n",
    "                       \n",
    "    model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_model(path_save, 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
